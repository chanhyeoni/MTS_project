?cut
?quantile
cut(merged_one$Ranking, breaks = quantile(data$Ranking, probs = seq(0,1, by = 0.2), na.rm = TRUE))
cut(merged_one$Ranking, breaks = quantile(merged_one$Ranking, probs = seq(0,1, by = 0.2), na.rm = TRUE))
a = cut(merged_one$Ranking, breaks = quantile(merged_one$Ranking, probs = seq(0,1, by = 0.2), na.rm = TRUE))
table(a, merged_one$IncomeGroup)
table(a, merged_one$Income.Group)
quantile(merged_one$Ranking, probs = seq(0,1, by = 0.2), na.rm = TRUE)
library(datasets)#
library(lattice)
splom(~airquality[1:5], groups = Month, data=airquality)
histogram(Ozone ~ Wind | Month, data = airquality, layout=c(5,1))
stripplot(Ozone ~ Wind | Month, data = airquality, layout=c(5,1))
?subset
g <- ggplot(data = mpg, aes(x = cty,y = hwy))
install.packages("ggplot2")
library(ggplot2)
g <- ggplot(data = mpg, aes(x = cty,y = hwy))
g + geom_point()
g + geom_point(aes(color = fl), size = 3, alpha = 1/2)
g + geom_point(aes(color= fl)) + theme_light()
g + geom_point(aes(color= fl)) + theme_bw()
g + geom_line()
g + geom_point(aes(color = fl)) + #
	labs(title = "MPG DATA") + # title is added#
	labs(x = "a", y = "b")
g+ geom_line() + geom_smooth(method = "lm")
g + geom_point(aes(color = fl), size = 3, alpha = 1/2)
qplot(displ, data = mpg, geom = "point", color = drv)
qplot(displ, hwy, data = mpg, colour = fl)
qplot(displ, hwy, data = mpg, facets = drv~., colour = fl)
qplot(displ, hwy, data = mpg, facets = drv~., method = "lm", colour = fl)
qplot(displ, hwy, data = mpg, method = "lm", colour = fl)
?qplot
qplot(cyl, year, data=mpg, facets= fl ~ class)
g + geom_point(aes(color = fl), size = 3, alpha = 1/2)
g + geom_point(aes(color = fl), size = 3, alpha = 1/2)+theme_bw()
g + geom_point() + geom_smooth()
g + geom_point(aes(color = fl), size = 3) + geom_smooth(method = "lm") + theme_bw()
fileURL <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"#
download.file(fileURL, destfile = "./Programming/Data Science/Getting and Cleaning Data/restaurants.csv", method = "curl")#
data <- read.csv("./Programming/Data Science/Getting and Cleaning Data/restaurants.csv")
data$nearMe =  data$neighborhood %in% c("Roland Park","Homeland")#
#
# creating a binary table#
data$wrongZipCode = ifelse(data$zipCode < 0, TRUE, FALSE)
table(data$wrongZipCode, data$zipCode <0)
data$zipGroups = cut(data$zipCode, breaks = quantile(data$zipCode, probs = c(0.3, 0.5, 0.8))
)
table(data$zipGroups)
install.packages("Hmisc")#
library(Hmisc)
str(data)
table(data$zipCode, data$policeDistrict)
xt <- xtabs(councilDistrict ~ zipCode + policeDistrict, data = data)
xt
ftable(xt)
colnames(ftable(xt))
install.packages("Hmisc")#
library(Hmisc)
data$zipGroups = cut2(data$zipCode, g = 5)#
table(data$zipGroups)
?melt
install.packages("reshape2")#
library(reshape2)#
data(mtcars)
?melt
mtcars$carname <- rownames(mtcars)#
carMelt <- melt(mtcars, id = c("carname", "cyl"), measure.vars = c("mpg", "hp"))
carMelt
str(carMelt)
str(mtcars)
install.packages("reshape2")#
library(reshape2)#
data(mtcars)
mtcars$carname <- rownames(mtcars)
str(mtcars)
carMelt <- melt(mtcars, id = c("carname", "cyl"), measure.vars = c("mpg", "hp"))
str(carMelt)
fileURL <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"#
download.file(fileURL, destfile = "./Programming/Data Science/Getting and Cleaning Data/restaurants.csv", method = "curl")#
data <- read.csv("./Programming/Data Science/Getting and Cleaning Data/restaurants.csv")
table(data$wrongZipCode, data$zipCode <0)
data$nearMe <-  data$neighborhood %in% c("Roland Park","Homeland")
data$wrongZipCode <- ifelse(data$zipCode < 0, TRUE, FALSE)
table(data$wrongZipCode, data$zipCode <0)
data$zipGroups = cut(data$zipCode, breaks = quantile(data$zipCode, probs = c(0.3, 0.5, 0.8)))#
table(data$zipGroups)
str(data)
?cut
quantile(data$zipCode, probs = c(0.3, 0.5, 0.8))
data$zipGroups = cut(data$zipCode, breaks = 4)
able(data$zipGroups)
table(data$zipGroups)
?quantile
data$zipGroups = cut(data$zipCode, breaks = quantile(data$zipCode, probs = c(0.3, 0.5, 0.8), na.rm=TRUE))
table(data$zipGroups)
table(data$zipCode, data$policeDistrict)
xt <- xtabs(councilDistrict ~ zipCode + policeDistrict, data = data)
xt
ftable(xt)
install.packages("Hmisc")#
library(Hmisc)
cylData <- dcast(carMelt, cyl ~ variable)
mtcars$carname <- rownames(mtcars)#
carMelt <- melt(mtcars, id = c("carname", "cyl"), measure.vars = c("mpg", "hp"))
str(carMelt)
cylData <- dcast(carMelt, cyl ~ variable)
cylData <- dcast(carMelt, cyle ~ variable, mean)
cylData <- dcast(carMelt, cyl ~ variable, mean)
str(cylData)
cylData <- dcast(carMelt, cyl ~ variable, sum)
table(cylData)
ftable(cylData)
fileURL <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType = DOWNLOAD"#
download.file(fileURL, destfile = "./cameras.csv", method = "curl")#
data <- read.csv("cameras.csv")#
names(data)
splitnames = strsplit(names(iris), "\\.")
splitnames
splitnames[[1]]
sapply(splitnames, function(x){x[1]})
?runif
pal <- colorRamp(c("red", "blue"))
pal
pal(0)
pal(0.3)
pal(seq(0,1, len = 10))
pal <- colorRampPalette(c("red", "yellow"))
pa
pal
pal(2)
pal(10)
library(RColorBrewer)
cols <- brewer.pal(3, "BuGn")
cols
pal <- colorRampPalette(cols)
image(volcano)
image(volcano, col = 5)
image(colcano, col = pal(5))
image(volcano, col = pal(5))
image(volcano, col = pal(12))
image(volcano, col = pal(20))
image(volcano, col = pal(50))
?smoothScatter
X <- rnorm(10000)#
y <- rnorm(10000)#
# uses the brew palette #
smootheScatter(X,y)
smoothScatter(X,y)
?smoothScatter
pal(20)
smoothScatter(X,y, colramp = colorRampPalette(cols))
library(colorspace)
plot(X,y,pch = 15)
plot(X,y, pch = 15, col = rgb(0,0,0,0.2))
plot(X,y, pch = 15, col = rgb(0,0,0,0.5))
plot(X,y, pch = 15, col = rgb(0,0,0,0.01))
plot(X,y, pch = 15, col = rgb(0.01,0,0,0.02))
plot(X,y, pch = 15, col = rgb(0.5,0,0,0.02))
?rgb
plot(X,y, pch = 15, col = rgb(0.7,0.4,0.2,0.02))
X <- rnorm(1000)#
y <- rnorm(1000)
plot(X,y, pch = 15, col = rgb(0.7,0.4,0.2,0.02))
plot(X,y, pch = 15, col = rgb(0.7,0.4,0.2,0.5))
plot(X,y, pch = 15, col = rgb(0.7,0.4,0.2,0.3))
plot(X,y, pch = 15, col = rgb(0.1,0.1,0.1,0.3))
import oauth
?oauth
??oauth
load("/Users/chlee021690/Desktop/RData 3")
RData 3
load("/Users/chlee021690/Desktop/RData 3")
~/Desktop/RData 3
open("/Users/chlee021690/Desktop/RData 3")
a = matrix(1:10)
a
a = matrix(1:10, 2:20)
a
a = matrix(1:100, nrow = 10, ncol = 10)
a
b = a[seq(1,5), seq(1,4)]
b
a = [[1,3], [2,3]]
a = matrix(seq(1,10))
a
sum(a,1)
sum(a,2)
sum(a)
?matri
?matrix
a = matrix(seq(1,10), nrow = 2, ncol = 5)
a
sum(a,1)
?sum
rowSum(a)
?rowsum
rowSums(a)
colSums(a)
?log
?log10
log10(a)
a[a==1] = 0
a
a = matrix(c(1,2,1,2,1,1,2,2,1,1), nrow = 2, ncol = 5)
a
a[a==2] = 0
a
rep(a)
a
?rep
repmat()
repmat
?repmat
a = list(a)
a
rep(a,2)
a = matrix(c(1,2,1,2,1,1,2,2,1,1), nrow = 2, ncol = 5)
a
a[1,]
b = a[1,]
a
b
cbind(b,b)
cbind(b,4)
rep(b,4)
rep(t(b),4)
matrix(rep(b,4), ncol=4)
?mean
?lapply
a = matrix(seq(1,16), ncol = 4, nrow = 4)
a
mean(a)
lapply(a, mean)
apply(a, mean)
sapply(a, mean)
tapply(a, mean)
colMeans(a)
a
b <- (a[a==2]=0)
b
a = matrix(c(1,2,1,2,1,1,2,2,1,1), nrow = 2, ncol = 5)
a[1, grep(a[1,]==1)]
grep?
?grep
which(a[1,]==1)
grep(a[1,]==1)
grep(a[1,]==1, a)
a[1, which(a[1,]==1)]
a
?row
install.packages("caret")
library(caret)
?caret
??caret
?kernlab
??kernlab
install.pakcages("kernlab")
install.packages("kernlab")
library(kernlab)
?kernlab
??kernlab
install.packages("shiny")
setwd("./Google Drive/MTS/MTS project")
dataset_1 <- read.csv("liberty_mutual_train.csv", nrow = 100000)
id <- dataset_1[, "id"]#
labels <- dataset_1[, "target"]#
dataset <- dataset_1[, !(colnames(dataset_1) %in% c("id", "target", "dummy"))]#
columns <- colnames(dataset_1)
labels[labels >= 1] = 1#
labels[labels < 1 ] = 0#
# separate them from positive and negative examples#
abnormal<- dataset[labels == 1, ]#
normal <- dataset[labels ==0, ]#
abnormal_mat <- as.matrix(abnormal)#
normal_mat <- as.matrix(normal)
crimes_data_normal <- normal[, grep("crime", columns)]#
crimes_data_abnormal <- abnormal[, grep("crime", columns)]
corr <- cor(crimes_data_normal, crimes_data_normal)#
inv_corr <- solve(corr)
dim(crimes_data_abnormal)
crimes_data_normal
dim(crimes_data_normal)
outside_group <- mahalanobis(crimes_data_abnormal, crimes_data_abnormal, corr, inverted = TRUE)
outside_group <- mahalanobis(as.matrix(crimes_data_abnormal), as.matrix(crimes_data_abnormal), corr, inverted = TRUE)
mahalanobis_distance <- function(data, inv_corr){#
	#calculate the mahalanobis distnace and returns the values diagonally positioned#
	# in the matrices#
	# divide the values by k (do this AFTER finding the correlation matrix?????)#
	front <- data/(as.numeric(length(colnames(data))))#
	# compute the distance	#
	distances <- (front %*% inv_corr) %*% t(data)#
	# obtain the diagonals#
	group <- diag(distances)#
	return (group)#
}
outside_group <- mahalanobis_distance(as.matrix(crimes_data_abnormal), inv_corr)
outside_group
