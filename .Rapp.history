colnames(merged_one)
colnames(file2)
colnames(file_2)
colnames(file_1)
merged_one
merge
merged_one
?match
count<- match(file_1[, "CountryCode"], file_2[, "CountryCode"])
count
length(count)
?na.rm
??na.rm
count<- match(file_1[, "CountryCode"], file_2[, "CountryCode"], na.rm = TRUE)
count[!is.na(count)]
length(count[!is.na(count)])
file_1[, "CountryCode"]
file_2[, "CountryCode"]
colnames(file_2)
colnames(merged_one)
merged_one[, "Income.Group"]
tapply(merged_one$Ranking, merged_one$Income.Group, mean)
tapply(merged_one$Ranking, merged_one$Income.Group, mean, na.rm= TRUE)
cut(merged_one$Ranking, breaks = quantile(data$Ranking, probs = seq(0,1, by = 0.2))
)
cut(merged_one$Ranking, breaks = quantile(data$Ranking, probs = seq(0,1, by = 0.2)), na.rm = TRUE)
colnames(merged_one)
?cut
?quantile
cut(merged_one$Ranking, breaks = quantile(data$Ranking, probs = seq(0,1, by = 0.2), na.rm = TRUE))
cut(merged_one$Ranking, breaks = quantile(merged_one$Ranking, probs = seq(0,1, by = 0.2), na.rm = TRUE))
a = cut(merged_one$Ranking, breaks = quantile(merged_one$Ranking, probs = seq(0,1, by = 0.2), na.rm = TRUE))
table(a, merged_one$IncomeGroup)
table(a, merged_one$Income.Group)
quantile(merged_one$Ranking, probs = seq(0,1, by = 0.2), na.rm = TRUE)
library(datasets)#
library(lattice)
splom(~airquality[1:5], groups = Month, data=airquality)
histogram(Ozone ~ Wind | Month, data = airquality, layout=c(5,1))
stripplot(Ozone ~ Wind | Month, data = airquality, layout=c(5,1))
?subset
g <- ggplot(data = mpg, aes(x = cty,y = hwy))
install.packages("ggplot2")
library(ggplot2)
g <- ggplot(data = mpg, aes(x = cty,y = hwy))
g + geom_point()
g + geom_point(aes(color = fl), size = 3, alpha = 1/2)
g + geom_point(aes(color= fl)) + theme_light()
g + geom_point(aes(color= fl)) + theme_bw()
g + geom_line()
g + geom_point(aes(color = fl)) + #
	labs(title = "MPG DATA") + # title is added#
	labs(x = "a", y = "b")
g+ geom_line() + geom_smooth(method = "lm")
g + geom_point(aes(color = fl), size = 3, alpha = 1/2)
qplot(displ, data = mpg, geom = "point", color = drv)
qplot(displ, hwy, data = mpg, colour = fl)
qplot(displ, hwy, data = mpg, facets = drv~., colour = fl)
qplot(displ, hwy, data = mpg, facets = drv~., method = "lm", colour = fl)
qplot(displ, hwy, data = mpg, method = "lm", colour = fl)
?qplot
qplot(cyl, year, data=mpg, facets= fl ~ class)
g + geom_point(aes(color = fl), size = 3, alpha = 1/2)
g + geom_point(aes(color = fl), size = 3, alpha = 1/2)+theme_bw()
g + geom_point() + geom_smooth()
g + geom_point(aes(color = fl), size = 3) + geom_smooth(method = "lm") + theme_bw()
fileURL <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"#
download.file(fileURL, destfile = "./Programming/Data Science/Getting and Cleaning Data/restaurants.csv", method = "curl")#
data <- read.csv("./Programming/Data Science/Getting and Cleaning Data/restaurants.csv")
data$nearMe =  data$neighborhood %in% c("Roland Park","Homeland")#
#
# creating a binary table#
data$wrongZipCode = ifelse(data$zipCode < 0, TRUE, FALSE)
table(data$wrongZipCode, data$zipCode <0)
data$zipGroups = cut(data$zipCode, breaks = quantile(data$zipCode, probs = c(0.3, 0.5, 0.8))
)
table(data$zipGroups)
install.packages("Hmisc")#
library(Hmisc)
str(data)
table(data$zipCode, data$policeDistrict)
xt <- xtabs(councilDistrict ~ zipCode + policeDistrict, data = data)
xt
ftable(xt)
colnames(ftable(xt))
install.packages("Hmisc")#
library(Hmisc)
data$zipGroups = cut2(data$zipCode, g = 5)#
table(data$zipGroups)
?melt
install.packages("reshape2")#
library(reshape2)#
data(mtcars)
?melt
mtcars$carname <- rownames(mtcars)#
carMelt <- melt(mtcars, id = c("carname", "cyl"), measure.vars = c("mpg", "hp"))
carMelt
str(carMelt)
str(mtcars)
install.packages("reshape2")#
library(reshape2)#
data(mtcars)
mtcars$carname <- rownames(mtcars)
str(mtcars)
carMelt <- melt(mtcars, id = c("carname", "cyl"), measure.vars = c("mpg", "hp"))
str(carMelt)
fileURL <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"#
download.file(fileURL, destfile = "./Programming/Data Science/Getting and Cleaning Data/restaurants.csv", method = "curl")#
data <- read.csv("./Programming/Data Science/Getting and Cleaning Data/restaurants.csv")
table(data$wrongZipCode, data$zipCode <0)
data$nearMe <-  data$neighborhood %in% c("Roland Park","Homeland")
data$wrongZipCode <- ifelse(data$zipCode < 0, TRUE, FALSE)
table(data$wrongZipCode, data$zipCode <0)
data$zipGroups = cut(data$zipCode, breaks = quantile(data$zipCode, probs = c(0.3, 0.5, 0.8)))#
table(data$zipGroups)
str(data)
?cut
quantile(data$zipCode, probs = c(0.3, 0.5, 0.8))
data$zipGroups = cut(data$zipCode, breaks = 4)
able(data$zipGroups)
table(data$zipGroups)
?quantile
data$zipGroups = cut(data$zipCode, breaks = quantile(data$zipCode, probs = c(0.3, 0.5, 0.8), na.rm=TRUE))
table(data$zipGroups)
table(data$zipCode, data$policeDistrict)
xt <- xtabs(councilDistrict ~ zipCode + policeDistrict, data = data)
xt
ftable(xt)
install.packages("Hmisc")#
library(Hmisc)
cylData <- dcast(carMelt, cyl ~ variable)
mtcars$carname <- rownames(mtcars)#
carMelt <- melt(mtcars, id = c("carname", "cyl"), measure.vars = c("mpg", "hp"))
str(carMelt)
cylData <- dcast(carMelt, cyl ~ variable)
cylData <- dcast(carMelt, cyle ~ variable, mean)
cylData <- dcast(carMelt, cyl ~ variable, mean)
str(cylData)
cylData <- dcast(carMelt, cyl ~ variable, sum)
table(cylData)
ftable(cylData)
fileURL <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType = DOWNLOAD"#
download.file(fileURL, destfile = "./cameras.csv", method = "curl")#
data <- read.csv("cameras.csv")#
names(data)
splitnames = strsplit(names(iris), "\\.")
splitnames
splitnames[[1]]
sapply(splitnames, function(x){x[1]})
?runif
pal <- colorRamp(c("red", "blue"))
pal
pal(0)
pal(0.3)
pal(seq(0,1, len = 10))
pal <- colorRampPalette(c("red", "yellow"))
pa
pal
pal(2)
pal(10)
library(RColorBrewer)
cols <- brewer.pal(3, "BuGn")
cols
pal <- colorRampPalette(cols)
image(volcano)
image(volcano, col = 5)
image(colcano, col = pal(5))
image(volcano, col = pal(5))
image(volcano, col = pal(12))
image(volcano, col = pal(20))
image(volcano, col = pal(50))
?smoothScatter
X <- rnorm(10000)#
y <- rnorm(10000)#
# uses the brew palette #
smootheScatter(X,y)
smoothScatter(X,y)
?smoothScatter
pal(20)
smoothScatter(X,y, colramp = colorRampPalette(cols))
library(colorspace)
plot(X,y,pch = 15)
plot(X,y, pch = 15, col = rgb(0,0,0,0.2))
plot(X,y, pch = 15, col = rgb(0,0,0,0.5))
plot(X,y, pch = 15, col = rgb(0,0,0,0.01))
plot(X,y, pch = 15, col = rgb(0.01,0,0,0.02))
plot(X,y, pch = 15, col = rgb(0.5,0,0,0.02))
?rgb
plot(X,y, pch = 15, col = rgb(0.7,0.4,0.2,0.02))
X <- rnorm(1000)#
y <- rnorm(1000)
plot(X,y, pch = 15, col = rgb(0.7,0.4,0.2,0.02))
plot(X,y, pch = 15, col = rgb(0.7,0.4,0.2,0.5))
plot(X,y, pch = 15, col = rgb(0.7,0.4,0.2,0.3))
plot(X,y, pch = 15, col = rgb(0.1,0.1,0.1,0.3))
splitnames = strsplit(names(iris), "\\.")
splitnames
splitnames = strsplit(names(iris), ".")
splitnames
splitnames = strsplit(names(iris), "\\.")
sapply(splitnames, function(x){x[1]})
sapply(splitnames, function(x){x[2]})
fileURL1 = "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"#
fileURL2 = "htpps://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"#
#
setwd("./Programming/Data Science/Getting and Cleaning Data")#
download.file(fileURL1, destfile = "./reviews.csv", method = "curl")#
download.file(fileURL2, destfile = "./solutions.csv", method = "curl")#
reviews <- read.csv("reviews.csv")#
solutions <- read.csv("solutions.csv")
?sub
grep("virginica", iris$Species)
grepl("virginica", iris$Species)
iris[grepl("virginica", iris$Species), ]
subplot(x,y,100)
subplot(2,2,1)
?strsplit
setwd("./Programming/Data Science/Exploratory Analysis/Household_power_consumption_project")#
#
# read the data#
NEI <- readRDS("./exdata-data-NEI_data/summarySCC_PM25.rds")#
SCC <- readRDS("./exdata-data-NEI_data/Source_Classification_Code.rds")#
install.packages("png")#
library(png)
getwd()
setwd("")
setwd("..")
getwd()
setwd("Exploratory Analysis/Household_power_consumption_project")
NEI <- readRDS("./exdata-data-NEI_data/summarySCC_PM25.rds")#
SCC <- readRDS("./exdata-data-NEI_data/Source_Classification_Code.rds")#
install.packages("png")#
library(png)
NEI$Emissions <- as.numeric(NEI$Emissions)#
# add new attribute, Year, which is the factored version of year#
NEI <- transform(NEI, year = factor(year))
str(NEI)
?aggregate
NEI_1 <- aggregate(NEI$Emissions, by=list(NEI$year))
NEI_1 <- aggregate(NEI$Emissions, by=list(NEI$year), FUN=sum)
str(NEI_1)
NEI_baltimore<-subset(NEI, fips=="24510")#
#
## extract SCC where "On-Road" is in "EI.Sector"-column#
mobile<-subset(SCC, grepl("On-Road", EI.Sector))#
#
## merge the 2 data frames#
total<-merge(NEI_baltimore, mobile, by="SCC")#
#
## calculate the sums by year#
sums <- aggregate(total$Emissions, by=list(total$year), FUN=sum)#
#
## change the column names#
names(sums)<-c("year", "sum_of_emissions")#
#
## build the plot#
plot(sums$year, sums$sum_of_emissions, xlab="Year", ylab="Total emissions", main="Total emissions by motor vehicles in Baltimore City")#
lines(sums$year, sums$sum_of_emissions)#
#
## write plot to png#
dev.copy(png,"plot5.png")#
dev.off()
library(data.table)#
library(ggplot2)#
#
## subset the dataset for Baltimore City and LA county#
NEI_balt_LA<-subset(NEI, fips=="24510" | fips=="06037")#
#
## extract SCC where "On-Road" is in "EI.Sector"-column#
mobile<-subset(SCC, grepl("On-Road", EI.Sector))#
#
## merge the 2 data frames#
total<-merge(NEI_balt_LA, mobile, by="SCC")#
#
## rename the fips codes to the corresponding counties#
total[total=="06037"]<-"LA County"#
total[total=="24510"]<-"Baltimore City"#
#
##remove certain columns that we don't need for the graphs#
total<-subset(total, select = c(Emissions, fips, year))#
#
## rename the fips column#
colnames(total)[2]<-"County"#
#
## transform to data table and calculate sums by type and year#
total<-data.table(total)#
total_grouped<-total[,lapply(.SD, sum), by=list(County, year)]#
#
## build the plot#
ggplot(total_grouped, aes(x=year, y = Emissions, color=County))+#
        geom_point()+#
        geom_line()+#
        ggtitle("Total motor vehicle emissions")#
#
## write plot to png#
dev.copy(png,"plot6.png")#
dev.off()
total_grouped
ggplot(total_grouped, aes(x=year, y = Emissions, color=County))+#
        geom_point()+#
        geom_line()+#
        ggtitle("Total motor vehicle emissions")
balLA <- rbind(baltim <- NEI[which(NEI$fips == "24510"), ], lax <- NEI[which(NEI$fips == "06037"), ])#
balLA$fips[which(balLA$fips == "24510")] <- "Baltimore City"#
balLA$fips[which(balLA$fips == "06037")] <- "Los Angeles County"#
names(balLA)[1] <- "Cities"#
#
# plot the graph and save #
png(file = "plot6.png", bg = "transparent")#
g1 <- ggplot(balLA, aes(x = year, y = Emissions, fill = Cities))#
g1 + geom_bar(stat = "identity", position = position_dodge())#
dev.off()
?laaply
?lapply
?data.frame
?sort
?aggregate
setwd("..")
getwd()
setwd("...")
setwd(".")
getwd()
setwd("..")
setwd("..")
setwd("..")
setwd("..")
getwd()
setwd("./chlee021690/Desktop/MTS/MTS sample for health")
normalize_mean <- function(dataFrame, k){#
	# obtain the mean meatrix#
	mean_data <- apply(dataFrame, 2, mean)#
	mean_data_mat <- matrix(mean_data, nrow = k, ncol = dim(dataFrame)[1] )#
	mean_data_mat <- t(mean_data_mat)#
	return (mean_data_mat)#
}#
#
normalize_sd <- function(dataFrame, k){#
	#obtain standard deviation matrix#
	sd_data <- apply(dataFrame, 2, sd)#
	sd_data_mat <- matrix(sd_data, nrow = k, ncol = dim(dataFrame)[1]  )#
	sd_data_mat <- t(sd_data_mat)#
	return (sd_data_mat)#
}#
mahalanobis_distance <- function(k, data, inv_corr){#
	#calculate the mahalanobis distnace#
	# divide the values by k (do this AFTER finding the correlation matrix?????)#
	front <- data/k#
	# change the data.frame into matrix framework#
	data <- as.matrix(data)#
	inv_corr <- as.matrix(inv_corr)#
	front <- as.matrix(front)#
	# compute the distance	#
	distances <- (front %*% inv_corr) %*% t(data)#
	# obtain the diagonals#
	group <- diag(distances)#
	return (group)#
}
k = 4#
#
# read the data#
library(xlsx)#
healthy<- read.xlsx("healthy_group.xlsx", sheetIndex = 1, header = 1)#
unhealthy <- read.xlsx("abnormal_group.xlsx", sheetIndex = 1, header = 1)#
# need to put header as 1 because it reads the first row of the excel as the attributes#
#
healthy <- healthy[, 2:length(colnames(healthy))]#
unhealthy <- unhealthy[, 2:length(colnames(unhealthy))]#
#normalize the data#
mean_healthy_mat <- normalize_mean(healthy, k)#
sd_healthy_mat <- normalize_sd(healthy, k)#
healthy <- (healthy - mean_healthy_mat)/sd_healthy_mat#
row_unhealthy <- dim(unhealthy)[1]#
unhealthy <- (unhealthy - (mean_healthy_mat[seq(1:row_unhealthy), ]) )/(sd_healthy_mat[seq(1:row_unhealthy), ])#
#
# find the inverse of correlation matrix for the healthy group#
corr <- cor(healthy, healthy)#
inv_corr <- solve(corr)#
#
# estimate the distances and obtain the diagonal parts of the matrix#
ref_group <- mahalanobis_distance(k, healthy, inv_corr)#
outside_group <- mahalanobis_distance(k, unhealthy, inv_corr)
ref_group
outside_group
install.packages("ggplot2")#
library(ggplot2)
plot(1:10, outside_group)
ref_group_data <- data.frame(distances = ref_group, label = "reference")#
	outside_group_data <- data.frame(distances = outside_group, label = "outside")#
	dataset <- rbind(ref_group_data, outside_group_data)	#
	nData <- 1:dim(ref_group_data)[1]
?dplyr
??dplyr
?plyr
??plyr
nData <- 1:dim(ref_group_data)[1]
x <- seq(1, nData)
nData
?plot
nData_outside <- 1:dim(outside_group_data)[1]
plot(x = nData, y = ref_group_data$distances, type = 'b')
plot(x = nData, y = ref_group_data$distances, type = 'b', col = 'red')
plot(x = nData, y = ref_group_data$distances, type = 'l', col = 'red')
lines(x = nData_outside, y = outside_group_data$distances, type = 'b', col = 'blue')
with(subset(airquality, Month == 7), points(Wind, Ozone, pch = 16, col="red"))
airquality
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in NYC"), type = "n")
with(subset(airquality, Month == 7), points(Wind, Ozone, pch = 16, col="red"))
with(ref_group_data, plot(x = nData_ref, y = ref_group_data$distances, type = 'l', col = 'red'), type = 'n')
nData_ref <- 1:dim(ref_group_data)[1]
with(ref_group_data, plot(x = nData_ref, y = ref_group_data$distances, type = 'l', col = 'red'), type = 'n')
with(outside_group_data, lines(x = nData_outside, y = outside_group_data$distances, type = 'l', col = 'blue'), type = 'n')
datasets
dataset
with(dataset, plot(x = nData_ref, y = ref_group_data$distances, type = 'l', col = 'red'), type = 'n')#
	with(dataset, lines(x = nData_outside, y = outside_group_data$distances, type = 'l', col = 'blue'), type = 'n')
with(dataset, plot(x = nData_ref, y = ref_group_data$distances, type = 'l', col = 'red'), type = 'n')#
	with(dataset, lines(x = nData_outside, y = outside_group_data$distances, type = 'l', col = 'blue'), type = 'n')
with(dataset, plot(x = nData_ref, y = ref_group_data$distances, type = 'l', col = 'red'), type = 'n')#
	with(dataset, points(x = nData_outside, y = outside_group_data$distances, type = 'l', col = 'blue'), type = 'n')
with(dataset, plot(x = nData_ref, y = ref_group_data$distances, type = 'l', col = 'red'), type = 'n')#
	with(dataset, points(x = nData_outside, y = outside_group_data$distances, type = 'l', col = 'blue'), type = 'n')
